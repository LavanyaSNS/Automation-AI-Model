# -*- coding: utf-8 -*-
"""BMC automation model by Ollama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vWbhAoSg2eNocCEBsxz_-KqnqUTd1cyu

Step 1: Install all necessary libraries including yt-dlp, whisper, and LLaMA-related packages from Hugging Face.

Step 2: Import all required modules.

Step 3: Download the audio from the YouTube video using yt-dlp.

Step 4: Use Whisper to transcribe the audio into text.

Step 5: Load the LLaMA model and tokenizer from Hugging Face for verification tasks.

Step 6: Perform quantitative verification by checking key elements such as student introductions, problem statements, speaking times, and coverage of the 9 BMC topics.

Step 7: Perform qualitative verification of the presentation based on speech patterns, clarity, and tone.

Step 8: Generate a detailed verification report that includes both quantitative and qualitative feedback.

Step 9: Combine all steps into the main function to extract the transcript and generate the verification report for any YouTube video.
"""

# Step 1: Install necessary libraries
!pip install yt-dlp whisper transformers accelerate torch

# Install or upgrade Whisper
!pip install git+https://github.com/openai/whisper.git

# Step 2: Import necessary libraries
import yt_dlp
import whisper
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import os

# Step 3: Download the YouTube video with yt-dlp
def download_audio_from_youtube(video_url, output_path="audio.mp3"):
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': output_path,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
                           }],
                }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            ydl.download([video_url])
        except Exception as e:
            print(f"Error downloading video: {e}")
            return None
    return output_path

# Step 4: Transcribe audio using Whisper
def transcribe_audio(audio_file):
    model = whisper.load_model("base")
    result = model.transcribe(audio_file)
    return result['text']

# Main function
def extract_text_from_youtube(video_url):
    audio_file = download_audio_from_youtube(video_url)
    if audio_file:
        transcript = transcribe_audio(audio_file)
        # Insert line breaks after every 100 characters for better readability
        formatted_transcript = '\n'.join([transcript[i:i+100] for i in range(0, len(transcript), 100)])
        return formatted_transcript
    else:
        return "Failed to download audio."

# Step 5: Load the LLaMA model from Hugging Face for verification
def load_llama_model():
    model_name = "meta-llama/Llama-2-7b-chat-hf"  # "meta-llama/Llama-3.2-1B"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")
    return model, tokenizer

# Step 6: Perform Quantitative Verification
def quantitative_verification(transcript, model, tokenizer):
    prompt = f"""
    Analyze the following transcription from a student BMC video submission and verify the following:
    - Do all students introduce themselves and mention their name?
    - Is the problem statement slide presented and explained?
    - Does each student speak for approximately one minute on their assigned topics?
    - Are all 9 BMC topics covered:
        (1) Business model key partners,
        (2) Key activities,
        (3) Value propositions,
        (4) Customer relationships,
        (5) Customer segments,
        (6) Key resources,
        (7) Channels,
        (8) Cost structure,
        (9) Revenue streams?
    Transcript: {transcript}
    """

    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")  # Use GPU if available
    outputs = model.generate(**inputs, max_length=1000)
    result = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return result

# Step 7: Perform Qualitative Verification
def qualitative_verification(transcript, model, tokenizer):
    prompt = f"""
    Analyze the following transcription for presentation quality:
    - Evaluate the tone, clarity, and engagement of each speaker.
    - Detect any issues like unclear speech, low volume, or excessive background noise.
    - Assess the overall presentation style, logical flow, and body language based on speech patterns.
    Transcript: {transcript}
    """

    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")  # Use GPU if available
    outputs = model.generate(**inputs, max_length=1000)
    result = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return result

# Step 8: Generate a detailed verification report
def generate_verification_report(transcript):
    model, tokenizer = load_llama_model()

    quantitative_result = quantitative_verification(transcript, model, tokenizer)
    qualitative_result = qualitative_verification(transcript, model, tokenizer)

    report = f"""
    Verification Report:

    Quantitative Analysis:
    {quantitative_result}

    Qualitative Analysis:
    {qualitative_result}

    Feedback:
    Please review the flagged elements and resubmit if necessary.
    """

    return report

'''# Step 9: Main function to extract text from YouTube and perform verification
def extract_and_verify(video_url):
    audio_file = download_audio_from_youtube(video_url)
    if audio_file:
        transcript = transcribe_audio(audio_file)
        # Perform verification
        report = generate_verification_report(transcript)
        print("Verification Report: \n", report)
    else:
        print("Failed to download or transcribe video.")'''

# Main function to download audio, transcribe, and verify
def extract_and_verify(video_url):
    transcript = extract_text_from_youtube(video_url)  # Get the transcription
    if "Failed to download audio." not in transcript:  # Check if transcription was successful
        verification_report = generate_verification_report(transcript)  # Generate verification report
        print(verification_report)  # Display the report
    else:
        print(transcript)  # Display error message if audio download fails

# Example usage
video_url = 'https://youtu.be/MgrpWsfbLNU'
extract_and_verify(video_url)